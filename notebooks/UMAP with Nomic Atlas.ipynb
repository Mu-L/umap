{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![umap in atlas](https://docs.nomic.ai/img/umap-with-nomic-atlas.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import requests\n",
    "\n",
    "def play(url):\n",
    "\tresponse = requests.get(url)\n",
    "\tresponse.raise_for_status()\n",
    "\thtml = f'<video width=1000 controls autoplay loop><source src=\"{url}\" type=\"video/mp4\"></video>'\n",
    "\treturn HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP with Nomic Atlas\n",
    "\n",
    "UMAP is available as a projection in Nomic Atlas, which creates interactive maps of your data with AI analysis, vector search APIs, and additional resources like duplicate detection and topic label generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Visualizing text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=1000 controls autoplay loop><source src=\"https://assets.nomicatlas.com/airline-reviews-umap.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play('https://assets.nomicatlas.com/airline-reviews-umap.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_date</th>\n",
       "      <th>published_platform</th>\n",
       "      <th>rating</th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-12T14:41:14-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>review</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>Ok</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11T19:39:13-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11T12:20:23-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "      <td>review</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>Don’t give them your money</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11T07:12:27-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>review</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>Best Airline in the World</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-10T05:34:18-04:00</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>0</td>\n",
       "      <td>review</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              published_date published_platform  rating    type  \\\n",
       "0  2024-03-12T14:41:14-04:00            Desktop       1  review   \n",
       "1  2024-03-11T19:39:13-04:00            Desktop       2  review   \n",
       "2  2024-03-11T12:20:23-04:00            Desktop       0  review   \n",
       "3  2024-03-11T07:12:27-04:00            Desktop       2  review   \n",
       "4  2024-03-10T05:34:18-04:00            Desktop       0  review   \n",
       "\n",
       "                                                text  \\\n",
       "0  We used this airline to go from Singapore to L...   \n",
       "1  The service on Singapore Airlines Suites Class...   \n",
       "2  Booked, paid and received email confirmation f...   \n",
       "3  Best airline in the world, seats, food, servic...   \n",
       "4  Premium Economy Seating on Singapore Airlines ...   \n",
       "\n",
       "                                               title  helpful_votes id  \n",
       "0                                                 Ok              0  0  \n",
       "1  The service in Suites Class makes one feel lik...              0  1  \n",
       "2                         Don’t give them your money              0  2  \n",
       "3                          Best Airline in the World              0  3  \n",
       "4  Premium Economy Seating on Singapore Airlines ...              0  4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "df = pd.read_csv(\"https://docs.nomic.ai/singapore_airlines_reviews.csv\")\n",
    "df['id'] = df.index.astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to Nomic Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-10 21:07:19.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m867\u001b[0m - \u001b[1mOrganization name: `nomic`\u001b[0m\n",
      "\u001b[32m2025-05-10 21:07:19.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m895\u001b[0m - \u001b[1mCreating dataset `example-dataset-airline-reviews`\u001b[0m\n",
      "\u001b[32m2025-05-10 21:07:20.200\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_validate_and_correct_arrow_upload\u001b[0m:\u001b[36m334\u001b[0m - \u001b[33m\u001b[1mReplacing 1 null values for field title with string 'null'. This behavior will change in a future version.\u001b[0m\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.46s/it]\n",
      "\u001b[32m2025-05-10 21:07:23.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1702\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2025-05-10 21:07:24.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCreated map `0196bce1-e7c2-5b15-31cd-ddd20c4fb6f4` in dataset `nomic/example-dataset-airline-reviews`: https://atlas.nomic.ai/data/nomic/example-dataset-airline-reviews\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nomic import AtlasDataset\n",
    "from nomic.data_inference import ProjectionOptions\n",
    "\n",
    "dataset = AtlasDataset(\"example-dataset-airline-reviews\", unique_id_field=\"id\")\n",
    "\n",
    "dataset.add_data(df)\n",
    "\n",
    "atlas_map = dataset.create_index(\n",
    "    indexed_field='text',\n",
    "    projection=ProjectionOptions(\n",
    "      model=\"umap\",\n",
    "      n_neighbors=20,\n",
    "      min_dist=0.01,\n",
    "      n_epochs=200\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Visualizing MNIST Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=1000 controls autoplay loop><source src=\"https://assets.nomicatlas.com/umap-with-nomic-atlas.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play('https://assets.nomicatlas.com/umap-with-nomic-atlas.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from nomic import AtlasDataset\n",
    "import time\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 3e-6\n",
    "BATCH_SIZE = 128\n",
    "NUM_VIS_SAMPLES = 3000\n",
    "EMBEDDING_DIM = 128\n",
    "ATLAS_DATASET_NAME = \"mnist_training_embeddings\"\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 28680519.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1419897.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 10652550.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2080433.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Training on 60000 samples, visualizing 3000 test samples per epoch.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 1. Define PyTorch Model ---\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # 28x28 -> 14x14\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # 14x14 -> 7x7\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, embedding_dim) # Embedding layer\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(embedding_dim, 10) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        embeddings = self.relu3(self.fc1(x))\n",
    "        output = self.fc2(embeddings)\n",
    "        return output, embeddings\n",
    "\n",
    "# --- 2. Load MNIST Data ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader for training\n",
    "# Handle persistent_workers based on device type (MPS doesn't support it well)\n",
    "persistent_workers_flag = True if device.type not in ['mps', 'cpu'] else False\n",
    "num_workers_val = 2 if persistent_workers_flag else 0 # num_workers > 0 can cause issues on MPS without persistent_workers\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers_val, persistent_workers=persistent_workers_flag if num_workers_val > 0 else False)\n",
    "\n",
    "# Create a subset of the test dataset for visualization\n",
    "vis_indices = list(range(NUM_VIS_SAMPLES))\n",
    "vis_subset = Subset(test_dataset, vis_indices)\n",
    "test_loader_for_vis = DataLoader(vis_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers_val, persistent_workers=persistent_workers_flag if num_workers_val > 0 else False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Training on {len(train_dataset)} samples, visualizing {NUM_VIS_SAMPLES} test samples per epoch.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Batch [200/469], Avg Loss: 2.2695\n",
      "Epoch [1/15], Batch [400/469], Avg Loss: 2.1794\n",
      "Epoch 1/15 training finished in 16.47s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 1.\n",
      "\n",
      "Epoch [2/15], Batch [200/469], Avg Loss: 2.0083\n",
      "Epoch [2/15], Batch [400/469], Avg Loss: 1.8469\n",
      "Epoch 2/15 training finished in 16.46s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 2.\n",
      "\n",
      "Epoch [3/15], Batch [200/469], Avg Loss: 1.6037\n",
      "Epoch [3/15], Batch [400/469], Avg Loss: 1.4239\n",
      "Epoch 3/15 training finished in 18.34s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 3.\n",
      "\n",
      "Epoch [4/15], Batch [200/469], Avg Loss: 1.2073\n",
      "Epoch [4/15], Batch [400/469], Avg Loss: 1.0713\n",
      "Epoch 4/15 training finished in 17.51s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 4.\n",
      "\n",
      "Epoch [5/15], Batch [200/469], Avg Loss: 0.9194\n",
      "Epoch [5/15], Batch [400/469], Avg Loss: 0.8350\n",
      "Epoch 5/15 training finished in 16.78s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 5.\n",
      "\n",
      "Epoch [6/15], Batch [200/469], Avg Loss: 0.7345\n",
      "Epoch [6/15], Batch [400/469], Avg Loss: 0.6731\n",
      "Epoch 6/15 training finished in 16.13s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 6.\n",
      "\n",
      "Epoch [7/15], Batch [200/469], Avg Loss: 0.6075\n",
      "Epoch [7/15], Batch [400/469], Avg Loss: 0.5695\n",
      "Epoch 7/15 training finished in 15.94s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 7.\n",
      "\n",
      "Epoch [8/15], Batch [200/469], Avg Loss: 0.5225\n",
      "Epoch [8/15], Batch [400/469], Avg Loss: 0.4935\n",
      "Epoch 8/15 training finished in 16.91s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 8.\n",
      "\n",
      "Epoch [9/15], Batch [200/469], Avg Loss: 0.4583\n",
      "Epoch [9/15], Batch [400/469], Avg Loss: 0.4419\n",
      "Epoch 9/15 training finished in 15.41s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 9.\n",
      "\n",
      "Epoch [10/15], Batch [200/469], Avg Loss: 0.4121\n",
      "Epoch [10/15], Batch [400/469], Avg Loss: 0.3969\n",
      "Epoch 10/15 training finished in 14.82s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 10.\n",
      "\n",
      "Epoch [11/15], Batch [200/469], Avg Loss: 0.3743\n",
      "Epoch [11/15], Batch [400/469], Avg Loss: 0.3682\n",
      "Epoch 11/15 training finished in 14.88s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 11.\n",
      "\n",
      "Epoch [12/15], Batch [200/469], Avg Loss: 0.3526\n",
      "Epoch [12/15], Batch [400/469], Avg Loss: 0.3389\n",
      "Epoch 12/15 training finished in 15.22s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 12.\n",
      "\n",
      "Epoch [13/15], Batch [200/469], Avg Loss: 0.3208\n",
      "Epoch [13/15], Batch [400/469], Avg Loss: 0.3189\n",
      "Epoch 13/15 training finished in 15.80s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 13.\n",
      "\n",
      "Epoch [14/15], Batch [200/469], Avg Loss: 0.3055\n",
      "Epoch [14/15], Batch [400/469], Avg Loss: 0.2993\n",
      "Epoch 14/15 training finished in 14.86s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 14.\n",
      "\n",
      "Epoch [15/15], Batch [200/469], Avg Loss: 0.2830\n",
      "Epoch [15/15], Batch [400/469], Avg Loss: 0.2890\n",
      "Epoch 15/15 training finished in 14.80s.\n",
      "\n",
      "Collected 3000 embeddings for visualization in epoch 15.\n",
      "\n",
      "Total training and embedding extraction time: 249.81s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# --- 3. Initialize Model, Optimizer, Criterion ---\n",
    "model = MNIST_CNN(embedding_dim=EMBEDDING_DIM).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 4. Training Loop & Embedding Extraction ---\n",
    "all_embeddings_list = []\n",
    "all_metadata_list = []\n",
    "all_images_html = []  # Store HTML representations of images\n",
    "\n",
    "# Helper function to convert tensor to HTML image\n",
    "def tensor_to_html(tensor):\n",
    "    # Denormalize the image\n",
    "    img = tensor.clone().detach().cpu().squeeze(0)\n",
    "    img = img * 0.3081 + 0.1307  # Reverse the normalization\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "\n",
    "    \n",
    "    img_pil = Image.fromarray((img.numpy() * 255).astype('uint8'), mode='L')\n",
    "    buffered = io.BytesIO()\n",
    "    img_pil.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    \n",
    "    return f'<img src=\"data:image/png;base64,{img_str}\" width=\"28\" height=\"28\">'\n",
    "\n",
    "overall_start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 200 == 0: # Print every 200 mini-batches\n",
    "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], Avg Loss: {running_loss / 200:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} training finished in {time.time() - epoch_start_time:.2f}s.\\n\")\n",
    "\n",
    "    # Extract embeddings for visualization subset\n",
    "    model.eval()\n",
    "    vis_samples_collected_this_epoch = 0\n",
    "    image_offset_in_vis_subset = 0 # Tracks the index within the vis_subset (0 to NUM_VIS_SAMPLES-1)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_for_vis:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            _, embeddings_batch = model(data)\n",
    "            for i in range(embeddings_batch.size(0)):\n",
    "                # original_idx_in_subset is the true index of this image within the NUM_VIS_SAMPLES selected for visualization\n",
    "                original_idx_in_subset = image_offset_in_vis_subset + i \n",
    "                if original_idx_in_subset >= NUM_VIS_SAMPLES: # Should not happen if test_loader_for_vis is setup correctly\n",
    "                    continue\n",
    "                \n",
    "                all_embeddings_list.append(embeddings_batch[i].cpu().numpy())\n",
    "                \n",
    "                # Generate HTML representation of the image\n",
    "                img_html = tensor_to_html(data[i])\n",
    "                all_images_html.append(img_html)\n",
    "                \n",
    "                all_metadata_list.append({\n",
    "                    'id': f'vis_img_{original_idx_in_subset}_epoch_{epoch}', # Unique ID for Atlas\n",
    "                    'epoch': epoch,\n",
    "                    'label': f'Digit: {target[i].item()}',\n",
    "                    'vis_sample_idx': original_idx_in_subset, # Index within the 0..NUM_VIS_SAMPLES-1 range\n",
    "                    'image_html': img_html  # Add the HTML representation to metadata\n",
    "                })\n",
    "                vis_samples_collected_this_epoch += 1\n",
    "            image_offset_in_vis_subset += embeddings_batch.size(0) # Move offset by batch size\n",
    "            if vis_samples_collected_this_epoch >= NUM_VIS_SAMPLES: # Ensure we don't collect more than needed\n",
    "                break\n",
    "                \n",
    "    print(f\"Collected {vis_samples_collected_this_epoch} embeddings for visualization in epoch {epoch+1}.\\n\")\n",
    "\n",
    "total_script_time = time.time() - overall_start_time\n",
    "print(f\"Total training and embedding extraction time: {total_script_time:.2f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 15:02:50.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m804\u001b[0m - \u001b[1mLoading existing dataset `nomic/mnist-training-embeddings`.\u001b[0m\n",
      "100%|██████████| 9/9 [00:12<00:00,  1.42s/it]\n",
      "\u001b[32m2025-05-11 15:03:03.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1702\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nomic import AtlasDataset\n",
    "\n",
    "dataset = AtlasDataset(\"mnist-training-embeddings\", unique_id_field='id')\n",
    "dataset.add_data(data=all_metadata_list, embeddings=np.array(all_embeddings_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-11 15:03:25.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1289\u001b[0m - \u001b[1mCreated map `0196c0bb-07a7-f93a-5c4d-15ab8c640e70` in dataset `nomic/mnist-training-embeddings`: https://atlas.nomic.ai/data/nomic/mnist-training-embeddings\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Atlas Projection 0196c0bb-07a7-f93a-5c4d-15ab8c640e70. Status Building Map. <a target=\"_blank\" href=\"https://atlas.nomic.ai/data/nomic/mnist-training-embeddings/map\">view online</a>"
      ],
      "text/plain": [
       "0196c0bb-07a7-f93a-5c4d-15ab8c640e70: https://atlas.nomic.ai/data/nomic/mnist-training-embeddings"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.create_index(projection='umap', topic_model=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your map in Atlas will look something like the above video."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
